---
name: parallel-ai-search
description: Web search + URL extraction via Parallel Search/Extract APIs. Use for up-to-date research, domain-scoped searching, and extracting LLM-ready excerpts/markdown from URLs.
homepage: https://docs.parallel.ai/search/search-quickstart
metadata: {"openclaw":{"emoji":"üîé","homepage":"https://docs.parallel.ai/","requires":{"bins":["node"],"env":["PARALLEL_API_KEY"]},"primaryEnv":"PARALLEL_API_KEY"}}
---

# Parallel AI Search (OpenClaw skill)

Use this skill to run web research through **Parallel Search** (ranked, LLM-optimised excerpts) and **Parallel Extract** (clean markdown from specific URLs, including JS-heavy pages and PDFs).

The skill ships tiny **Node .mjs** helpers so the agent can call the APIs deterministically via the OpenClaw **exec** tool.

## Quick start

### 1) Provide the API key

Prefer configuring it in `~/.openclaw/openclaw.json` (host runs):

```json5
{
  skills: {
    entries: {
      "parallel-ai-search": {
        enabled: true,
        apiKey: "YOUR_PARALLEL_API_KEY"
      }
    }
  }
}
```

Notes:
- If the agent run is **sandboxed**, the Docker sandbox does **not** inherit host env. Provide the key via `agents.defaults.sandbox.docker.env` (or bake it into the image).
- This skill is gated on `PARALLEL_API_KEY`. If it‚Äôs missing, OpenClaw won‚Äôt load the skill.

### 2) Run a search

Use **exec** to run:

```bash
node {baseDir}/scripts/parallel-search.mjs \
  --objective "When was the United Nations established? Prefer UN websites." \
  --query "Founding year UN" \
  --query "Year of founding United Nations" \
  --max-results 5 \
  --mode one-shot
```

### 3) Extract content from URLs

```bash
node {baseDir}/scripts/parallel-extract.mjs \
  --url "https://www.un.org/en/about-us/history-of-the-un" \
  --objective "When was the United Nations established?" \
  --excerpts \
  --no-full-content
```

### 4) One command: search ‚Üí extract top results

```bash
node {baseDir}/scripts/parallel-search-extract.mjs \
  --objective "Find recent research on quantum error correction" \
  --query "quantum error correction 2024" \
  --query "QEC algorithms" \
  --max-results 6 \
  --top 3 \
  --excerpts
```

## When to use

Trigger this skill when the user asks for:
- ‚ÄúParallel search‚Äù, ‚Äúparallel.ai search‚Äù, ‚ÄúParallel Extract‚Äù, ‚ÄúSearch API‚Äù, ‚ÄúExtract API‚Äù
- ‚Äúweb research with Parallel‚Äù, ‚ÄúLLM-optimised excerpts‚Äù, ‚Äúsource_policy/include_domains‚Äù, ‚Äúafter_date‚Äù, ‚Äúfetch_policy‚Äù
- ‚Äúextract clean markdown from URL/PDF‚Äù, ‚Äúcrawl a JS-heavy page‚Äù, ‚Äúget fresh web results‚Äù

## Default workflow

1. **Search** with an *objective* + a few *search_queries*.
2. **Inspect** titles/URLs/publish dates; choose the best sources.
3. **Extract** the specific pages you actually need (top N URLs).
4. **Answer** using the extracted excerpts/full content.

Use **Search** to discover; use **Extract** to read.

## Best-practice prompting for Parallel

### Objective
Write 1‚Äì3 sentences describing:
- the real task context (why you need the info)
- freshness constraints (‚Äúprefer 2025+‚Äù, ‚Äúafter 2024-01-01‚Äù, ‚Äúuse latest docs‚Äù)
- preferred sources (‚Äúofficial docs‚Äù, ‚Äústandards bodies‚Äù, ‚ÄúGitHub releases‚Äù)

### search_queries
Add 3‚Äì8 keyword queries that include:
- the specific terms, version numbers, error strings
- common synonyms
- if relevant, date terms (‚Äú2025‚Äù, ‚Äú2026‚Äù, ‚ÄúJan 2026‚Äù)

### Mode
- Use `mode=one-shot` for single-pass questions (default).
- Use `mode=agentic` for multi-step research loops (shorter, more token-efficient excerpts).

### Source policy
When you need tight control, set `source_policy`:
- `include_domains`: allowlist (max 10)
- `exclude_domains`: denylist (max 10)
- `after_date`: RFC3339 date (`YYYY-MM-DD`) to filter for freshness

## Scripts

All scripts print a JSON response to stdout by default.

### `scripts/parallel-search.mjs`

Calls `POST https://api.parallel.ai/v1beta/search`.

Common flags:
- `--objective "..."`
- `--query "..."` (repeatable)
- `--mode one-shot|agentic`
- `--max-results N` (1‚Äì20)
- `--include-domain example.com` (repeatable)
- `--exclude-domain example.com` (repeatable)
- `--after-date YYYY-MM-DD`
- `--excerpt-max-chars N` (per result)
- `--excerpt-max-total-chars N` (across results)
- `--fetch-max-age-seconds N` (force freshness; 0 disables)
- `--request path/to/request.json` (advanced: full request passthrough)
- `--request-json '{"objective":"..."}'` (advanced)

### `scripts/parallel-extract.mjs`

Calls `POST https://api.parallel.ai/v1beta/extract`.

Common flags:
- `--url "https://..."` (repeatable, max 10)
- `--objective "..."`
- `--query "..."` (repeatable)
- `--excerpts` / `--no-excerpts`
- `--full-content` / `--no-full-content`
- `--excerpts-max-chars N` / `--excerpts-max-total-chars N`
- `--full-max-chars N`
- `--fetch-max-age-seconds N` (min 600 when set)
- `--fetch-timeout-seconds N`
- `--disable-cache-fallback`
- `--request path/to/request.json` (advanced)

### `scripts/parallel-search-extract.mjs`

Convenience pipeline:
1) Search
2) Extract the top N URLs from the search results (single Extract call)

Common flags:
- All `parallel-search.mjs` flags
- `--top N` (1‚Äì10)
- Extraction toggles: `--excerpts`, `--full-content`, plus the extract excerpt/full settings

## Output handling conventions

When turning API output into a user-facing answer:
- Prefer **official / primary sources** when possible.
- Quote or paraphrase **only** the relevant extracted text.
- Include **URL + publish_date** (when present) for transparency.
- If results disagree, present both and say what each source claims.

## Error handling

Scripts exit with:
- `0` success
- `1` unexpected error (network, JSON parse, etc.)
- `2` invalid arguments
- `3` API error (non-2xx) ‚Äî response body is printed to stderr when possible

## References

Load these only when needed:
- `references/parallel-api.md` ‚Äî compact API field/shape reference
- `references/openclaw-config.md` ‚Äî OpenClaw config + sandbox env notes
- `references/prompting.md` ‚Äî objective/query templates and research patterns
